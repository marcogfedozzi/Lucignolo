{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d55865",
   "metadata": {},
   "source": [
    "# MIMo Control Example\n",
    "\n",
    "In this notebook we'll see how to control \n",
    "\n",
    "Create a MIMo environment, then add a point in front of it and instruct the inverse dynamics controller to reach it.\n",
    "\n",
    "What we need:\n",
    "- MIMo environment\n",
    "- Inverse Dynamics controller\n",
    "- point to reach (for simplicity, a sequence with len = 1)\n",
    "- a translation task that connect one of MIMo's hands' End Effector with the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91a5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucignolo as lc\n",
    "import mimoEnv.utils as me_utils\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a477f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geoms_for_body_tree(sim_model, body_id):\n",
    "\t\"\"\"\n",
    "\tGet the range of geometries for a given body tree in the simulation model.\n",
    "\tArgs:\n",
    "\t\tsim_model (mujoco.MjModel): The Mujoco model object.\n",
    "\t\tbody_id (int): The id of the root body.\n",
    "\tReturns:\n",
    "\t\trange: The range of geometries IDs for the given body tree, or None if the geometries are not consecutive.\n",
    "\t\"\"\"\t\n",
    "\n",
    "\tbodies = me_utils.get_child_bodies(sim_model, body_id)\n",
    "\tgeoms = []\n",
    "\tfor body in sorted(bodies):\n",
    "\t\tgeoms.append(me_utils.get_geoms_for_body(sim_model, body))\n",
    "\t\t\n",
    "\tare_geoms_consecutive = True\n",
    "\n",
    "\tfor i in range(len(geoms)-1):\n",
    "\t\tare_geoms_consecutive = are_geoms_consecutive and geoms[i].stop == geoms[i+1].start\n",
    "\n",
    "\t\tif not are_geoms_consecutive:\n",
    "\t\t\treturn None\n",
    "\n",
    "\treturn range(geoms[0].start, geoms[-1].stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b47917",
   "metadata": {},
   "source": [
    "# Env\n",
    "\n",
    "We load the local version of the MIMo XML, that contains the \"EEF\" sites that \n",
    "we will use as end effectors for the inverse controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465923c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hypothe/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/envs/registration.py:728: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='human' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sensor points:  7258\n",
      "WARNING: OpenGL error 0x505 in or before mjr_makeContext\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_name = \"MIMoBench-v0\"\n",
    "max_steps = 10000\n",
    "\n",
    "file_path = os.getcwd()\n",
    "model_path = os.path.join(file_path, \"assets\", \"control.xml\") \n",
    "\n",
    "_render_mode = \"human\"\n",
    "\n",
    "# Note: the env is wrapped by default\n",
    "env: Wrapper = gym.make(env_name, model_path=model_path, render_mode=_render_mode) #, show_sensors=False, print_space_sizes=True)\n",
    "\n",
    "model, data = lc.core.utils.get_model_data(env)\n",
    "\n",
    "_init_steps = 0 #100\n",
    "env.reset()\n",
    "for _ in range(_init_steps):\n",
    "\tenv.step(np.zeros(env.action_space.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63b4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_body = \"left_hand\" \n",
    "\n",
    "geoms = get_geoms_for_body_tree(model, model.body(controlled_body).id)\n",
    "\n",
    "orig_contype = model.geom_contype[geoms]\n",
    "orig_conaff = model.geom_conaffinity[geoms]\n",
    "model.geom_contype[geoms] = 0\n",
    "model.geom_conaffinity[geoms] = 0\n",
    "\n",
    "\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "_render_video = not (_render_mode == \"human\")\n",
    "\n",
    "if _render_video:\n",
    "\tout = cv.VideoWriter(os.path.join(file_path, f\"reachtest_{controlled_body}.mp4\"), fourcc, int(1/env.get_wrapper_attr('dt')), (500, 500))\n",
    "\tdef render(env):\n",
    "\t\timg = env.render()\n",
    "\t\timg_bgr = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "\t\tout.write(img_bgr)\n",
    "\n",
    "else:\n",
    "\tdef render(env):\n",
    "\t\tenv.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2fbf0",
   "metadata": {},
   "source": [
    "In order to use the Inverse Dynamics Controller to move MIMo we need 3 objects:\n",
    "- a [target], the point in space we are intersted in\n",
    "- an [end effector], the point on MIMo we want to control\n",
    "- one or more [field(s)], the mathematical relation between the [target] and the [end effector]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545afed",
   "metadata": {},
   "source": [
    "# Target\n",
    "\n",
    "A [target] is a mocap body defined in the scene XML. In the 'control.xml' scene we are using here\n",
    "we defined 3 targets, one for the head and one for each hand. Note that this is a simple convention,\n",
    "as any target could be associated to any end effector, in a many-to-many configuration!\n",
    "\n",
    "We can choose among different types of frames, but if we want to be able to move the\n",
    "target around in real time we can default to 'ControllableFrame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb383d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = lc.core.frames.ControllableFrame(env, \"target:\"+controlled_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374eee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.xpos = np.array([0.2, 0.0, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0319a",
   "metadata": {},
   "source": [
    "We can also choose to position the target with respect to a geometry on MIMo's body (or anything else). But be sure to keep in mind that the new frame will be positioned w.r.t. the current orientation of the body, and that you might need to run the simulation for some step before reaching a stable, initial, state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14507c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We clip to avoid falling below the floor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is the relative position w.r.t. MIMo\"\"\"\n",
    "#rel_target_position = np.asarray([0.4, 0, -0.1])\n",
    "\n",
    "\"We pass from relative to world coordinates (mimo_location is the root of MIMo's model)\"\n",
    "#w_target_position = me_utils.body_pos_to_world(data, rel_target_position, model.body('head').id)\n",
    "\n",
    "\"\"\"We clip to avoid falling below the floor\"\"\"\n",
    "#w_target_position[2] = np.clip(w_target_position[2], 0.1, 0.5)\n",
    "\n",
    "#logging.info(f\"Setting target at relative position {rel_target_position}, world position {w_target_position}\")\n",
    "\n",
    "#target.xpos = w_target_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce82686",
   "metadata": {},
   "source": [
    "# End Effector\n",
    "\n",
    "An [end effector] (EEF) is a 'site' object defined in MIMo's xml. \n",
    "By inspecting that file ('assets/mimo/MIMo_model(v2).xml') you can see we defined an EEF\n",
    "for the head, one for each eye, and one for each hand.\n",
    "The location in the body tree determines where the site is located on MIMo's body.\n",
    "Every site here defined is located in the center of the respective body part, and\n",
    "oriented with the 'z' azis exiting perpendicular to its surface \n",
    "(head -> pointing where the nose points, eye -> optical axis, hand -> exiting from the palm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179394a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eef_frame = lc.core.frames.Frame(env, \"eef:\"+controlled_body, \"site\", heading=np.array([0,0,1]))\n",
    "\n",
    "eef = lc.core.eef_point.EEFPoint(eef_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04759a30",
   "metadata": {},
   "source": [
    "# Fields\n",
    "\n",
    "[field(s)] are nothinig but the mathematical formulation that describes the force that acts\n",
    "on the [EEF] given its relative 6D pose (translation, orientation) w.r.t. the [target].\n",
    "While any mathematical formulation is possible here, the most frequent one are readily available\n",
    "as specific functions.\n",
    "\n",
    "Let's add an attractive field that brings the hand towards the target (simple reach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1951dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "attractive_field = lc.fields.get_field(\n",
    "\tcenter=target,\n",
    "\tfield_type=\"translation\",\n",
    "\tparams={\n",
    "\t\t\"k\": 800.0,\n",
    "\t\t\"pow\": 1.0,\n",
    "\t\t\"max\": 0.1,\n",
    "\t}\n",
    ")\n",
    "eef.add_field(attractive_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17e0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alignment_field = lc.fields.get_field(\n",
    "\tcenter=target,\n",
    "\tfield_type=\"misalignment\",\n",
    "\tparams={\n",
    "\t\t\"k\": 100.0,\n",
    "\t\t\"pow\": 2.0,\n",
    "\t\t\"s\": 0.5,\n",
    "\t\t\"radii\": [0.1, 0.3] \n",
    "\t}\n",
    ")\n",
    "eef.add_field(alignment_field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f412c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viscous_field = lc.fields.get_field(\n",
    "\tcenter=target,\n",
    "\tfield_type=\"viscosity\",\n",
    "\tparams={\n",
    "\t\t\"k\": [20.0, 10],\n",
    "\t\t\"pow\": 1.0,\n",
    "\t}\n",
    ")\n",
    "eef.add_field(viscous_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210ac71",
   "metadata": {},
   "source": [
    "# Controller\n",
    "\n",
    "It's finally time to define our controller. For this we will pick the Inverse Dynamic controller, \n",
    "as we want to drive the [EEF] and we do not really care for what the joint do to move it.\n",
    "\n",
    "We will further specify that we do not want to move the whole MIMo body, but we only want to control\n",
    "the limb that the [EEF] is attached to. To achieve that we specify the subtree type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decc4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree_type = controlled_body if \"head\" in controlled_body or \"eye\" in controlled_body else controlled_body.replace(\"hand\", \"arm\")\n",
    "\n",
    "controller = lc.controllers.IDController(env, eef, subtree_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090e598",
   "metadata": {},
   "source": [
    "# Running the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52eb796b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[32m      3\u001b[39m \taction = controller.step()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \tobs, reward, done, trunc, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \trender(env)\n\u001b[32m      7\u001b[39m \t\u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m trunc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:125\u001b[39m, in \u001b[36mTimeLimit.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    114\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m._elapsed_steps += \u001b[32m1\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elapsed_steps >= \u001b[38;5;28mself\u001b[39m._max_episode_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/mimoEnv/envs/mimo_env.py:648\u001b[39m, in \u001b[36mMIMoEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28mself\u001b[39m.do_simulation(action, \u001b[38;5;28mself\u001b[39m.frame_skip)\n\u001b[32m    647\u001b[39m \u001b[38;5;28mself\u001b[39m._step_callback()\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m obs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28mself\u001b[39m._obs_callback()\n\u001b[32m    651\u001b[39m achieved_goal = \u001b[38;5;28mself\u001b[39m.get_achieved_goal()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/mimoEnv/envs/mimo_env.py:771\u001b[39m, in \u001b[36mMIMoEnv._get_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# robot vision:\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vision:\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m     vision_obs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_vision_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m vision_obs:\n\u001b[32m    773\u001b[39m         observation_dict[sensor] = vision_obs[sensor]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/mimoEnv/envs/mimo_env.py:735\u001b[39m, in \u001b[36mMIMoEnv.get_vision_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_vision_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    727\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Collects and returns the outputs of the vision system.\u001b[39;00m\n\u001b[32m    728\u001b[39m \n\u001b[32m    729\u001b[39m \u001b[33;03m    Override this function if you want to make some simple post-processing!\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    733\u001b[39m \u001b[33;03m        each eye renders one image, so each eye gets one entry.\u001b[39;00m\n\u001b[32m    734\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     vision_obs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vision_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vision_obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/mimoVision/vision.py:133\u001b[39m, in \u001b[36mSimpleVision.get_vision_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28mself\u001b[39m.env.camera_name = camera\n\u001b[32m    132\u001b[39m rgb_viewer.viewport = \u001b[38;5;28mself\u001b[39m._viewports[camera]\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._acuity_functions[camera] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# Apply age-dependent visual acuity\u001b[39;00m\n\u001b[32m    135\u001b[39m     img = \u001b[38;5;28mself\u001b[39m._apply_acuity(img, camera)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_env.py:158\u001b[39m, in \u001b[36mMujocoEnv.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    155\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    Render a frame from the MuJoCo simulation as specified by the render_mode.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmujoco_renderer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:765\u001b[39m, in \u001b[36mMujocoRenderer.render\u001b[39m\u001b[34m(self, render_mode)\u001b[39m\n\u001b[32m    762\u001b[39m viewer = \u001b[38;5;28mself\u001b[39m._get_viewer(render_mode=render_mode)\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m render_mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrgb_array\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdepth_array\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrgbd_tuple\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mviewer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m render_mode == \u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m viewer.render()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IIT/Lucignolo/.venv/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:266\u001b[39m, in \u001b[36mOffScreenViewer.render\u001b[39m\u001b[34m(self, render_mode, camera_id, segmentation)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m marker_params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._markers:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28mself\u001b[39m._add_marker_to_scene(marker_params)\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mmujoco\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmjr_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mviewport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gridpos, (text1, text2) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._overlays.items():\n\u001b[32m    269\u001b[39m     mujoco.mjr_overlay(\n\u001b[32m    270\u001b[39m         mujoco.mjtFontScale.mjFONTSCALE_150,\n\u001b[32m    271\u001b[39m         gridpos,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m         \u001b[38;5;28mself\u001b[39m.con,\n\u001b[32m    276\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for step in range(max_steps):\n",
    "\taction = controller.step()\n",
    "\tobs, reward, done, trunc, info = env.step(action)\n",
    "\trender(env)\n",
    "\n",
    "\tif done or trunc:\n",
    "\t\t\tenv.reset()\n",
    "\n",
    "if _render_video:\n",
    "\tout.release()\n",
    "\n",
    "print(\"Elapsed time: \", time.time() - start, \"Simulation time:\", max_steps*env.get_wrapper_attr('dt'))\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucignolo (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
